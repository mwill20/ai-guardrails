"""
CRITICAL VERIFICATION: Did Gate A validation use the NEW OWASP patterns?

This test will re-run Gate A validation and check:
1. Are the deterministic patterns being invoked?
2. Do we get pattern hit logs?
3. Is the FPR calculation still accurate?
"""

import json
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "src"))

from OWASP_Pipeline_Guardrail import run_guardrail_pipeline

print("=" * 100)
print("CRITICAL CHECK: Gate A Validation with OWASP Patterns")
print("=" * 100)
print()

# Load clean benign corpus
dataset_path = project_root / "datasets" / "Clean_Benign_Corpus_v1.jsonl"

prompts = []
with open(dataset_path, "r", encoding="utf-8") as f:
    for line in f:
        record = json.loads(line)
        prompts.append(record["prompt"])

print(f"Loaded {len(prompts)} benign prompts")
print()

# Test first 10 prompts with detailed logging
print("SAMPLE TEST: First 10 prompts")
print("=" * 100)

sample_blocked = []
sample_allowed = []

for i, prompt in enumerate(prompts[:10], 1):
    result = run_guardrail_pipeline(prompt)
    
    action = result["log_entry"]["action"]
    det_risk = result["deterministic_risk"]
    det_hits = result["deterministic_pattern_hits"]
    sem_label = result["semantic_result"]["label"]
    sem_score = result["semantic_result"]["score"]
    
    status = "üö´ BLOCKED" if action == "blocked" else "‚úì ALLOWED"
    
    print(f"\n[{i}] {status}")
    print(f"    Prompt: {prompt[:70]}...")
    print(f"    Deterministic: {det_risk} (patterns: {len(det_hits)})")
    if det_hits:
        print(f"      ‚ö†Ô∏è  OWASP patterns triggered:")
        for hit in det_hits:
            print(f"        - {hit['pattern']} [{hit['code']}]")
    print(f"    Semantic: {sem_label} (score: {sem_score:.4f})")
    print(f"    Combined: {result['combined_risk']}")
    
    if action == "blocked":
        sample_blocked.append({
            "prompt": prompt,
            "det_risk": det_risk,
            "det_hits": det_hits,
            "sem_label": sem_label,
            "sem_score": sem_score
        })
    else:
        sample_allowed.append(prompt)

print()
print("=" * 100)
print("FULL CORPUS VALIDATION")
print("=" * 100)

# Run full corpus
false_positives = []
true_negatives = []
deterministic_fps = 0  # FPs caused by deterministic layer
semantic_fps = 0        # FPs caused by semantic layer

for prompt in prompts:
    result = run_guardrail_pipeline(prompt)
    
    if result["log_entry"]["action"] == "blocked":
        # False positive - benign prompt blocked
        false_positives.append({
            "prompt": prompt,
            "deterministic_risk": result["deterministic_risk"],
            "deterministic_hits": result["deterministic_pattern_hits"],
            "semantic_label": result["semantic_result"]["label"],
            "semantic_score": result["semantic_result"]["score"],
            "combined_risk": result["combined_risk"]
        })
        
        # Classify source of FP
        if result["deterministic_pattern_hits"]:
            deterministic_fps += 1
        else:
            semantic_fps += 1
    else:
        true_negatives.append(prompt)

# Calculate metrics
total = len(prompts)
fp_count = len(false_positives)
tn_count = len(true_negatives)
fpr = (fp_count / total) * 100

print(f"Total benign prompts: {total}")
print(f"True Negatives (TN):  {tn_count} ({tn_count/total*100:.1f}%)")
print(f"False Positives (FP): {fp_count} ({fpr:.1f}%)")
print()

# Breakdown of FP sources
if fp_count > 0:
    print(f"FP Source Breakdown:")
    print(f"  Deterministic layer: {deterministic_fps} ({deterministic_fps/fp_count*100:.0f}%)")
    print(f"  Semantic layer:      {semantic_fps} ({semantic_fps/fp_count*100:.0f}%)")
    print()

# Gate A check
if fpr <= 2.0:
    print(f"‚úÖ GATE A PASSED: FPR = {fpr:.1f}% ‚â§ 2.0%")
else:
    print(f"‚ùå GATE A FAILED: FPR = {fpr:.1f}% > 2.0%")
print()

# Show FP details
if fp_count > 0:
    print("=" * 100)
    print("FALSE POSITIVE ANALYSIS")
    print("=" * 100)
    
    for i, fp in enumerate(false_positives, 1):
        print(f"\n[FP #{i}]")
        print(f"Prompt: {fp['prompt'][:80]}...")
        print(f"Deterministic: {fp['deterministic_risk']}")
        
        if fp['deterministic_hits']:
            print(f"  ‚ö†Ô∏è  DETERMINISTIC PATTERNS TRIGGERED (THIS IS THE ISSUE!):")
            for hit in fp['deterministic_hits']:
                print(f"    - Pattern: '{hit['pattern']}'")
                print(f"      Code: {hit['code']}")
                print(f"      Category: {hit['category']}")
        else:
            print(f"  ‚úì No deterministic patterns (FP from semantic layer)")
        
        print(f"Semantic: {fp['semantic_label']} (score: {fp['semantic_score']:.4f})")
        print(f"Combined: {fp['combined_risk']}")
        print("-" * 100)

print()
print("=" * 100)
print("CRITICAL FINDINGS")
print("=" * 100)

findings = []

if deterministic_fps > 0:
    findings.append(f"‚ùå CRITICAL: {deterministic_fps} FPs caused by NEW OWASP patterns!")
    findings.append(f"   Action needed: Review and disable problematic patterns")
else:
    findings.append(f"‚úÖ VERIFIED: Zero FPs from OWASP patterns")

if semantic_fps == fp_count and fp_count <= 2:
    findings.append(f"‚úÖ VERIFIED: All {fp_count} FPs from semantic layer (same as baseline)")
else:
    findings.append(f"‚ö†Ô∏è  FP distribution changed from baseline")

if fpr == 1.0:
    findings.append(f"‚úÖ VERIFIED: FPR maintained at baseline (1.0%)")
elif fpr <= 2.0:
    findings.append(f"‚úì FPR within Gate A threshold but increased from baseline")
else:
    findings.append(f"‚ùå FPR exceeded Gate A threshold (2.0%)")

for finding in findings:
    print(finding)

print()
print("=" * 100)
print("VERDICT")
print("=" * 100)

if deterministic_fps == 0 and fpr <= 2.0:
    print("‚úÖ RESULTS ARE LEGITIMATE")
    print("   - OWASP patterns are active and working")
    print("   - Zero deterministic false positives")
    print("   - FPR within acceptable threshold")
    print("   - Gate A validation is accurate")
else:
    print("‚ùå INVESTIGATION NEEDED")
    print("   - Review false positive sources above")
    print("   - Consider disabling problematic patterns")
